{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from models.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from base.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trial, model_id, nL, nN, lr, task, \\\n",
    "                x_dim, w_dim, k, n_epoch, mixed_weight, \\\n",
    "                x_train, w_train, y_train, x_te, w_te, y_te, \\\n",
    "                occ_train, det_train, occ_te, det_te, batch_size, P=1):\n",
    "\n",
    "    # For mini batches\n",
    "    params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 1}\n",
    "    dataset = TensorDataset(x_train, w_train, y_train, \\\n",
    "                torch.tensor(np.array(occ_train), dtype=torch.float32), \\\n",
    "                torch.tensor(np.array(det_train).reshape(x_train.shape[0], k), \\\n",
    "                             dtype=torch.float32))  \n",
    "    dataloader = DataLoader(dataset, **params)\n",
    "\n",
    "    # Model selection\n",
    "    torch.manual_seed(trial)\n",
    "    if model_id == 0:\n",
    "        model = OD_LR(x_dim, w_dim)\n",
    "    elif model_id == 1:\n",
    "        model = OD_1NN(x_dim, w_dim, k, nN)\n",
    "    elif model_id == 2:\n",
    "        occ_idx = 0\n",
    "        det_idx = 2\n",
    "        if nL == 1:\n",
    "            model = StatEcoNet_H1(x_dim, w_dim, nN)\n",
    "        elif nL == 3:\n",
    "            model = StatEcoNet_H3(x_dim, w_dim, nN)\n",
    "        else:\n",
    "            print(\"not available model\")\n",
    "            assert False\n",
    "    else:\n",
    "        print(\"not available model\")\n",
    "        assert False\n",
    "\n",
    "    # Set an optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Record training/testing results per iteration\n",
    "    test_auprc = []\n",
    "    df_train = pd.DataFrame(columns=['lr','batchSize','nLayers','nNeurons',\\\n",
    "                                     'nIter','loss','auroc','auprc',\\\n",
    "                                     'occCorr','detCorr'])\n",
    "    df_test = pd.DataFrame(columns=['lr','batchSize','nLayers','nNeurons',\\\n",
    "                                    'nIter','loss','auroc','auprc',\\\n",
    "                                    'occCorr','detCorr'])\n",
    "\n",
    "    # Start training a model\n",
    "    best_iter = 0\n",
    "    best_model = 0\n",
    "    best_elapse = 0\n",
    "    perfect = False\n",
    "    start = time.time()\n",
    "    for i in tqdm(range(n_epoch)):\n",
    "        # for mini batches\n",
    "        train_loss = []\n",
    "        train_y_true = []\n",
    "        train_occ_true = []\n",
    "        train_det_true = []\n",
    "        train_y_pred = []\n",
    "        train_occ_pred = []\n",
    "        train_det_pred = []\n",
    "        for i_batch, xy in enumerate(dataloader):\n",
    "            # load a minibatch\n",
    "            x_tr, w_tr, y_tr, occ_tr, det_tr = xy\n",
    "            train_y_true.extend(list(torch.flatten(y_tr).detach().numpy()))\n",
    "            train_occ_true.extend(list(torch.flatten(occ_tr).detach().numpy()))\n",
    "            train_det_true.extend(list(torch.flatten(det_tr).detach().numpy()))\n",
    "\n",
    "            # Train a model **************************************************\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            psi_hat_train, p_hat_train = model(x_tr, w_tr)\n",
    "            train_occ_pred.extend(\\\n",
    "                        list(torch.flatten(psi_hat_train).detach().numpy()))\n",
    "            train_det_pred.extend(\\\n",
    "                        list(torch.flatten(p_hat_train).detach().numpy()))\n",
    "\n",
    "            # Compute training loss\n",
    "            loss = my_loss_function(y_tr, psi_hat_train, p_hat_train, \\\n",
    "                                    x_tr.shape[0], k)\n",
    "            if mixed_weight:\n",
    "                params = list(model.parameters())\n",
    "                loss += mixed_weight * \\\n",
    "                        (torch.sum(torch.norm(params[occ_idx], dim=0)))**(1/P)\n",
    "                loss += mixed_weight * \\\n",
    "                        (torch.sum(torch.norm(params[det_idx], dim=0)))**(1/P)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # Compute Y from psi_hat and p_hat\n",
    "            NN_pred = p_hat_train.reshape(p_hat_train.shape[:2]) * \\\n",
    "                      torch.cat([psi_hat_train]*k, 1)\n",
    "            NN_pred = torch.flatten(NN_pred).detach().numpy()\n",
    "            train_y_pred.extend(list(NN_pred))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # After learning all samples\n",
    "        assert np.sum(train_y_true) == torch.sum(y_train)\n",
    "\n",
    "        # Compute accuracy on train Y ****************************************\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(train_y_true, train_y_pred)\n",
    "        auroc = metrics.auc(fpr, tpr)\n",
    "        precision, recall, thresholds = precision_recall_curve(train_y_true, \\\n",
    "                                                               train_y_pred)\n",
    "        auprc = metrics.auc(recall, precision)\n",
    "\n",
    "        # Compute correlation on prob.\n",
    "        occCorr = pearsonr(train_occ_true, train_occ_pred)[0]\n",
    "        detCorr = pearsonr(train_det_true, train_det_pred)[0]\n",
    "\n",
    "        # Record training results per iteration\n",
    "        df_train.loc[i] = [lr, batch_size, nL, nN, i, np.mean(train_loss), \\\n",
    "                           auroc, auprc, occCorr, detCorr]\n",
    "\n",
    "        # Evalaute the trained model *****************************************\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            psi_hat_test, p_hat_test = model(x_te, w_te)\n",
    "\n",
    "            # Compute test loss\n",
    "            loss_t = my_loss_function(y_te, psi_hat_test, p_hat_test, \\\n",
    "                                      x_te.shape[0], k)\n",
    "            if mixed_weight:\n",
    "                params = list(model.parameters())\n",
    "                loss_t += mixed_weight * \\\n",
    "                        (torch.sum(torch.norm(params[occ_idx], dim=0)))**(1/P)\n",
    "                loss_t += mixed_weight * \\\n",
    "                        (torch.sum(torch.norm(params[det_idx], dim=0)))**(1/P)            \n",
    "\n",
    "            # Compute Y from psi_hat and p_hat\n",
    "            NN_pred = p_hat_test.reshape(p_hat_test.shape[:2]) * \\\n",
    "                      torch.cat([psi_hat_test]*k, 1)\n",
    "            NN_pred = torch.flatten(NN_pred).detach().numpy()\n",
    "\n",
    "            # Compute accuracy on Y\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(torch.flatten(y_te), \\\n",
    "                                                     NN_pred)\n",
    "            auroc = metrics.auc(fpr, tpr)\n",
    "            precision, recall, thresholds = \\\n",
    "                        precision_recall_curve(torch.flatten(y_te), NN_pred)\n",
    "            auprc = metrics.auc(recall, precision)\n",
    "            test_auprc.append(auprc)\n",
    "\n",
    "            # CHECKING THE BEST ITERATION =================\n",
    "            if test_auprc[-1] == np.max(test_auprc):\n",
    "                best_iter = i\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_elapse = time.time() - start            \n",
    "            else:\n",
    "                if task == \"train\" and i > best_iter + 200:\n",
    "                    print(\"No more improvement. This is the early stop point.\")\n",
    "                    break\n",
    "            # =============================================\n",
    "\n",
    "            # Compute correlation on prob.\n",
    "            occCorr = pearsonr(occ_te.to_numpy().flatten(), \\\n",
    "                               psi_hat_test.detach().numpy().flatten())[0]\n",
    "            detCorr = pearsonr(det_te.to_numpy().flatten(), \\\n",
    "                               p_hat_test.detach().numpy().flatten())[0]\n",
    "\n",
    "            df_test.loc[i] = [lr, batch_size, nL, nN, i, loss_t.item(), \\\n",
    "                              auroc, auprc, occCorr, detCorr]\n",
    "\n",
    "    assert best_iter < n_epoch\n",
    "    if task == \"train\":\n",
    "        return df_train, df_test, best_iter, best_model, best_elapse\n",
    "    else:\n",
    "        return df_train, df_test, model, psi_hat_test, p_hat_test, NN_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_te, w_te, y_te, occ_te, det_te, k):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        psi_hat_test, p_hat_test = model(x_te, w_te)\n",
    "\n",
    "        # compute Y from psi_hat and p_hat\n",
    "        NN_pred = p_hat_test.reshape(p_hat_test.shape[:2]) * \\\n",
    "                  torch.cat([psi_hat_test]*k, 1)\n",
    "        NN_pred = torch.flatten(NN_pred).detach().numpy()\n",
    "\n",
    "        # compute accuracy on Y\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(torch.flatten(y_te), NN_pred)\n",
    "        auroc = metrics.auc(fpr, tpr)\n",
    "        precision, recall, thresholds = \\\n",
    "                        precision_recall_curve(torch.flatten(y_te), NN_pred)\n",
    "        auprc = metrics.auc(recall, precision)\n",
    "\n",
    "        # compute correlation on prob.\n",
    "        occCorr = pearsonr(occ_te.to_numpy().flatten(), \\\n",
    "                           psi_hat_test.detach().numpy().flatten())[0]\n",
    "        detCorr = pearsonr(det_te.to_numpy().flatten(), \\\n",
    "                           p_hat_test.detach().numpy().flatten())[0]\n",
    "\n",
    "        return(psi_hat_test, p_hat_test, NN_pred, \\\n",
    "               auroc, auprc, occCorr, detCorr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
